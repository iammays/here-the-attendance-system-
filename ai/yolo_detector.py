import cv2
import numpy as np
import pymongo
from insightface.app import FaceAnalysis
from scipy.spatial.distance import cosine
from pymongo import MongoClient
import os
import time

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù„Ø¯Ø§Øª Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±
os.makedirs("screenshots/raw", exist_ok=True)
os.makedirs("screenshots/faces", exist_ok=True)
os.makedirs("screenshots/unknown", exist_ok=True)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ArcFace
app = FaceAnalysis(providers=['CPUExecutionProvider'])
app.prepare(ctx_id=0, det_size=(640, 640))

# Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
mongo_client = MongoClient("mongodb://localhost:27017")
db = mongo_client["face_attendance"]
students_collection = db["students_embeddings"]

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
def load_student_embeddings():
    students_embeddings = {}
    students = students_collection.find({}, {"name": 1, "embedding": 1})
    for student in students:
        if "embedding" in student:
            students_embeddings[student["name"]] = np.array(student["embedding"], dtype=np.float32)
    print(f"âœ… Loaded {len(students_embeddings)} student embeddings.")
    np.save("students_embeddings_from_mongodb.npy", students_embeddings, allow_pickle=True)
    print("âœ… Saved embeddings from MongoDB to students_embeddings_from_mongodb.npy")
    return students_embeddings

students_embeddings = load_student_embeddings()

# Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬Ù‡
def recognize_face(face_embedding):
    best_match = None
    best_score = 1.0
    for student_name, stored_embedding in students_embeddings.items():
        score = cosine(face_embedding, stored_embedding)
        if score < best_score:
            best_score = score
            best_match = student_name
    if best_match and best_score < 0.5:
        print(f"âœ… Recognized: {best_match} (Similarity: {1 - best_score:.2f})")
        return best_match
    else:
        print("âŒ Face is unknown.")
        return "Unknown"

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ArcFace ÙÙ‚Ø·
def process_video_stream(video_path=0):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("âŒ Failed to open video or camera.")
        return

    last_screenshot_time = time.time()

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if time.time() - last_screenshot_time >= 1:  # ÙƒÙ„ Ø«Ø§Ù†ÙŠØ©
            timestamp = int(time.time())
            screenshot_path = f"screenshots/raw/frame_{timestamp}.jpg"
            cv2.imwrite(screenshot_path, frame)
            print(f"ğŸ“¸ Saved raw frame at {screenshot_path}")

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙØ±ÙŠÙ… Ø¥Ù„Ù‰ RGB ÙˆØªÙ…Ø±ÙŠØ±Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ ArcFace
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            detected_faces = app.get(frame_rgb)

            if detected_faces:
                print(f"ğŸ‘¥ Detected {len(detected_faces)} faces in frame")
                for i, face in enumerate(detected_faces):
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„ÙˆØ¬Ù‡
                    x1, y1, x2, y2 = face.bbox.astype(int)

                    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø¯Ø§Ø®Ù„ Ø­Ø¯ÙˆØ¯ Ø§Ù„ÙØ±ÙŠÙ…
                    x1 = max(0, x1)
                    y1 = max(0, y1)
                    x2 = min(frame.shape[1], x2)
                    y2 = min(frame.shape[0], y2)

                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ù…Ù‚ØµÙˆØµ
                    face_crop = frame[y1:y2, x1:x2]

                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† face_crop Ù„ÙŠØ³Øª ÙØ§Ø±ØºØ©
                    if face_crop.size == 0 or face_crop.shape[0] == 0 or face_crop.shape[1] == 0:
                        print(f"âš ï¸ Skipping empty face crop for face_{timestamp}_{i}")
                        continue

                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ† ÙˆØ§Ù„ØªØ¹Ø±Ù
                    face_embedding = face.embedding.flatten()
                    label = recognize_face(face_embedding)

                    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØµÙ†ÙŠÙ
                    if label == "Unknown":
                        face_path = f"screenshots/unknown/face_{timestamp}_{i}.jpg"
                    else:
                        face_path = f"screenshots/faces/face_{timestamp}_{i}.jpg"

                    # Ø­ÙØ¸ Ø§Ù„ÙˆØ¬Ù‡ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª
                    try:
                        cv2.imwrite(face_path, face_crop)
                        print(f"ğŸ–¼ï¸ Saved face at {face_path}")
                    except Exception as e:
                        print(f"âŒ Error saving face at {face_path}: {e}")

                    # Ø±Ø³Ù… Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„ ÙˆØ§Ù„ØªØ³Ù…ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„ÙØ±ÙŠÙ…
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            else:
                print("âŒ No faces detected in this frame by ArcFace.")

            last_screenshot_time = time.time()

        cv2.imshow("Video Stream", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

        time.sleep(0.05)

    cap.release()
    cv2.destroyAllWindows()